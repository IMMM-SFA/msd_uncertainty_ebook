.. _glossary:

========
Glossary
========

**Design of experiment**: Provides a framework for the extraction of all plausible information about the impact of each factor on the output of the numerical model

**Exploratory modeling**: Use of large ensembles of uncertain conditions to discover decision-relevant combinations of uncertain factors

**Factor**: Any model component that can affect model outputs: inputs, resolution levels, coupling relationships, model relationships and parameters. In models with acceptable model fidelity these factors may represent elements of the real-world system under study.

**Factor mapping**: A technique to identify which uncertain model factors lead to certain model behavior

**Factor prioritization**: A technique to identify the uncertain factors which, when fixed to their true value, would lead to the greatest reduction in output variability

**Factor screening**: A technique to identify model components that have a negligible effect or make no significant contributions to the variability of the outputs or metrics of interest

**First-, second-, total-order effects**: First-order effects indicate the percent of model output variance contributed by a factor individually. Second-order effects capture how interactions between a pair of parameter input variables can lead to change in model output. Total-order effects consider all the effects a factor has, individually and in interaction with other factors.

**Hindcasting**: A type of predictive check that uses the model to estimate output for past events to see how well the output matches the known results.

**Pre-calibration**: A hybrid uncertainty assessment method that involves identifying a plausible set of parameters using some prespecified screening criterion, such as the distance from the model results to the observations.

**Prior**: The best assessment of the probability of an event based on existing knowledge before a new experiment is conducted

**Posterior**: The revised or updated probability of an event after taking into account new information

**Probabilistic inversion**: Uses additional information, for instance, a probabilistic expert assessment or survey result, to update an existing prior distribution

**Return level**: A value that is expected to be equaled or exceeded on average once every interval of time (T) (with a probability of 1/T)

**Return period**: The estimated time interval between events of a similar size or intensity/

**Sampling**: The process of selecting model parameters or inputs that characterize the model uncertainty space.

**Scenario discovery**: Use of large ensembles of uncertain conditions to discover decision-relevant combinations of uncertain factors

**Sensitivity analysis**: Conducted to understand the factors and processes that most (or least) control a model’s outputs

	*Local sensitivity analysis*: Model evaluation performed by varying uncertain factors around specific reference values

	*Global sensitivity analysis*: Model evaluation performed by varying uncertain factors throughout their entire feasible value space

**Uncertainty**

*Deep uncertainty*: Refers to situations where expert opinions consulted on a decision do not know or cannot agree on system boundaries, or the outcomes of interest and their relative importance, or the prior probability Distribution for the various uncertain factors present

*Epistemic uncertainty*: Systematic uncertainty that comes about due to the lack of knowledge or data to choose the best model

*Ontological uncertainty*: Uncertainties due to processes, interactions, or futures, that are not contained within current conceptual models

*Aleatory uncertainty*: Uncertainty due to natural randomness in processes

*Uncertainty characterization*: Model evaluation under alternative factor hypotheses to explore their implications for model output uncertainty

*Uncertainty quantification*: Representation of model output uncertainty using probability distributions

**Variance decomposition**: A technique to partition how much of the variability in a model’s output is due to different explanatory variables.
