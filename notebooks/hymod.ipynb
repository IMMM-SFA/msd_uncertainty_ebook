{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Sensitivity Analysis of the HYMOD Model\n",
    "\n",
    "The purpose of this tutorial is to demonstrate the global sensitivity analysis concepts and tools established in the Section 3.1 of the main text of this eBook. This demonstration will highlight the central role of design of experiments (Section 3.3), when implementing global sensitivity analysis tools described in Section 3.4.\n",
    "\n",
    "We'll explore these tools and concepts using the HYdrological MODel (HYMOD), a rainfall-runoff model developed and used for river flow forecasting. HYMOD was chosen for demonstration because its purpose is to abstract highly complex and non-linear systems. The methods demonstrated in thistutorial can be applied to numerical models that simulate other complex non-linear systems.\n",
    "\n",
    "This tutorial will first introduce HYMOD and use it to simulate streamflows in a river basin. Next, we'll employ sensitivity analysis concepets described in Section 3 of the main text to examine how values of HYMOD's parameters impact streamflow predictions. We'll then explore how the effects of these parameters may change over time using time-varying sensitivtiy analysis. Finally, we'll demonstrate concepts presented in Chapter 7 through two ensemble-based methods of uncertainty quantification - Generalized Likelihood Uncertainty Estimation (GLUE) and Pre-Calibration. \n",
    "\n",
    "The tutorial includes the following steps:\n",
    "\n",
    "#### 1. Introduction to HYMOD\n",
    "[1.1 - Introduction to a simple hydrologic model (HYMOD)](#hymod) <br>\n",
    "[1.2 - Input Data](#inputs) <br>\n",
    "[1.3 - Running a basic simulation](#baseline) <br>\n",
    "[1.4 - Model outputs](#outputs) <br>\n",
    "\n",
    "#### 2. Global Sensitivity Analysis\n",
    "[2.1 - Design of Experiments](#sensitivity)  <br>\n",
    "[2.2 - Sensitivity analysis for one output](#sa_metrics)  <br>\n",
    "[2.3 - Sensitivity analysis across multiple outputs](#diff_performance) <br>\n",
    "[2.4 - Time-varying sensitivity analysis](#TVSA)  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction to HYMOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hymod'></a> \n",
    "# 1.1- Overview\n",
    "\n",
    "HYMOD is a hydrologic model (rainfall-runoff model) that simulates key hydrologic fluxes such as infiltration, streamflow and evapotranspiration. The model was originally developed and used for river flow forecasting, but it has also been been used to explore different sensitivity analysis (e.g., [Herman et al., 2013](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/wrcr.20124)), uncertainty quantification (e.g.,  [Smith et al., 2008](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2006WR005205)), and optimization (e.g., [Ye et al., 2014](https://www.sciencedirect.com/science/article/pii/S0022169414006362?casa_token=IRqE19Hkfa8AAAAA:_fXOqfwpzxMpchvu8_0njCe0Ok9H29Gyw2F46l9PzG9UVODDTUg6wIOSiyp6uybGevNVnZ7N)) concepts.\n",
    "\n",
    "HYMOD accepts two inputs - daily precepitation and daily potential evapotranspiration (PET)- and generates predicitons of daily streamflow. HYMOD abstracts the highly non-linear process of runoff routing by dividing the flow into two components: quick flow, representing precipitation that quickly runs off the surface of the watershed into the stream, and slow flow, that moves through the soil and takes much longer to arrive at the stream.\n",
    "\n",
    "To generate streamflow predictions, HYMOD first models vertical processes within the watershed to determine how much water infiltrates and evaporates from the soil at a given time step. It then determines how much water should be partitioned into quick flow and slow flow processes. Within each process it abstracts residence time (the time it takes a unit volume of water to move through the watershed and into the stream) using a series of \"reservoirs\" each with a calibrated residence time. \n",
    "\n",
    "HYMOD's representation of hydrologic processes are shown Figure 1 below and controlled by the following parameters:\n",
    "\n",
    "$H_{uz}$: the maximum water storage capacity of the soil (mm)\n",
    "\n",
    "$B_{exp}$: parameters describing the degree of spatial variability within the basin between 0 and Huz\n",
    "\n",
    "$Alp$:    Fraction of runoff contributing to quick flow \n",
    "\n",
    "$K_q$:     Quick flow residence time of linear infinite reservoir (the Kq values of all three linear reservoirs are the same)\n",
    "\n",
    "$K_s$:      Slow flow residence time of linear infinite reservoir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figs/hymod_schematic-DAVE.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical Processes\n",
    "\n",
    "HYMOD models the fraction of water that is stored in the soil $(F(XH_{uz}))$ using the following relationship:\n",
    "\n",
    "$$F(XH_{uz}) = 1 - (1 - \\frac{XH_{uz}}{H_{uz}})^{B}$$\n",
    "\n",
    "where *$XH_{uz}$* is the water storage capacity of the soil; **$H_{uz}$** is the parameter describing basin maximum water storage capacity (mm); and **$B$** is the parameter describing the degree of spatial variability within the basin. \n",
    "\n",
    "The portion of precipitation that exceeds the water storage capacity is treated as runoff.\n",
    "\n",
    "### Horizontal Processes\n",
    "To route runoff to streamflow, the excess runoff from the vertical processes is split into quick flow and slow flow. The proportion of runoff partitioned into quick flow and slow flow is determined by a parameter $Alp$, which ranges between 0 and 1. Quick flow is routed through $N$ identical quick flow tanks $Q1, Q2... QN$ (shown above as $N=3$). The rate at which runoff moves through the quick flow system is described by the residence time of the quick frlow tanks, $Kq$ (day). Slow flow is routed through a parallel slow flow tank and the rate at which slow flow is routed is described by the slow flow residences time, $Ks$ (day).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation: Wagener, T., Boyle, D. P., Lees, M. J., Wheater, H. S., Gupta, H. V., & Sorooshian, S. (2001). A framework for development and application of hydrological models. Hydrology and Earth System Sciences, 5(1), 13-26."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inputs'></a> \n",
    "### 1.2 Input data\n",
    "\n",
    "The HYMOD model only requires precipitation and potential evapotranspiration as inputs. For this example, we'll run HYMOD using data from the Leaf River, a humid catchment located north of Collins Mississippi that has been widely used to explore HYMOD. The dataset also includes daily observed runoff that we later use to evaluate the performace of each sensitvity analysis sample set. \n",
    "\n",
    "In the following section of code, we'll load the necessary python libraries and read in the input file. For this exercise we'll only use the first eleven years of data. The first five rows of the input dataset are printed to show what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msdbook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load example data\n",
    "msdbook.install_package_data()\n",
    "\n",
    "# load the Leaf River HYMOD input file\n",
    "leaf_data = msdbook.load_hymod_input_file()\n",
    "\n",
    "# extract the first eleven years of data\n",
    "leaf_data = leaf_data.iloc[0:4015].copy()\n",
    "\n",
    "print('Leaf River Data structure:')\n",
    "\n",
    "# There are only three columns in the file including precipitation, potential evapotranspiration and  streamflow\n",
    "leaf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize catchment hydrology, streamflow and precipitation data are usually plotted together as a combined hydrograph (streamflow ) and hyetograph (rainfall, from Greek.hyetos, “rain”). Streamflow is plotted as a time series, while rainfall is shown as an inverted bar plot along the top of the graph. Streamflow labels are shown on the left y-axis, while rainfall labels are shown on the right y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an axis for the hydrograph\n",
    "fig, strmflw_ax = plt.subplots(figsize=[12,6])\n",
    "strmflw_ax.set_ylim([0, 50])\n",
    "\n",
    "#make a second y-axis for the hyetograph\n",
    "precip_ax = strmflw_ax.twinx()\n",
    "precip_ax.set_ylim([0, 200])\n",
    "precip_ax.invert_yaxis()\n",
    "\n",
    "precip = leaf_data['Precip']\n",
    "strmflw_ax.plot(range(0, len(leaf_data['Precip'])), leaf_data['Strmflw'], color='lightcoral')\n",
    "strmflw_ax.set_ylabel('Streamflow (mm/day)')\n",
    "\n",
    "precip_ax.bar(range(0, len(leaf_data['Precip'])), leaf_data['Precip'], width=2)\n",
    "precip_ax.set_ylabel('Rainfall (mm/day)')\n",
    "precip_ax.legend(['Precip'], loc='center right')\n",
    "strmflw_ax.legend(['Streamflow'],bbox_to_anchor=(1, 0.48))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='baseline'></a> \n",
    "### 1.3 Running a Baseline Model Simulation\n",
    "\n",
    "We'll start our experiment by running HYMOD using its default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign input parameters to generate a baseline simulated streamflow\n",
    "Nq = 3  # Number of quickflow routing tanks \n",
    "Kq = 0.5 # Quickflow routing tanks' rate parameter    \n",
    "Ks =  0.001 # Slowflow routing tank's rate parameter           \n",
    "Alp = 0.5 # Quick/slow split parameter   \n",
    "Huz = 100 # Maximum height of soil moisture accounting tank  \n",
    "B = 1.0 # Scaled distribution function shape parameter    \n",
    "\n",
    "# Note that the number of years is 11. One year of model warm-up and ten years are used for actual simulation\n",
    "model = msdbook.hymod(Nq, Kq, Ks, Alp, Huz, B, leaf_data, ndays=4015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outputs'></a> \n",
    "### 1.4 Model Outputs\n",
    "\n",
    "Model outputs include actual evapotranspiration, quick and fast streamflow, and combined runoff. In this tutorial we focus on the total daily runoff, QQ ($m^3/s$). We can use the following script to plot simulated streamflow against observed streamflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> View the source code used to create this plot here:  <a href=\"https://immm-sfa.github.io/msd_uncertainty_ebook/docs/html/A3_plotting_code.html#plot-observed-vs-simulated-streamflow\">plot_observed_vs_simulated_streamflow</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msdbook.plot_observed_vs_simulated_streamflow(df=leaf_data, hymod_dict=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does our model perform? We can investigate model performance across several metrics:\n",
    "\n",
    "1: Mean Absolute Error (MAE);\n",
    "MAE conveys how the model performs on average across the 10 year simulation period, with smaller values indicating better performance. The absolute value is taken so that positive and negative errors do not cancel each other out.\n",
    "\n",
    "$$MAE = \\frac{1}{N}\\sum_{t=0}^N\\left\\lvert Q_{sim,t}-Q_{obs,t}\\right\\rvert$$\n",
    "\n",
    "2: Root Mean Square Error (RMSE);\n",
    "RMSE is sum of square errors across the 10 year simulation period. RMSE is sensitive to large errors between the historical record and the simulated flows, and thus is useful for highlighting the model's ability to capture of extreme flood events.\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{N}\\sum_{t=1}^{N}(Q_{sim,t}-Q_{obs,t})^2}$$\n",
    "\n",
    "3: Log-Root Mean Square Error (Log(RMSE))\n",
    "LOG(RMSE) focuses on model performance during low-flow events.\n",
    "\n",
    "$$LOG(RMSE) = log(RMSE)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(abs(leaf_data['Strmflw'] - model['Q']))\n",
    "mse = metrics.mean_squared_error(model['Q'], leaf_data['Strmflw'])\n",
    "rmse = mse**(1/2)\n",
    "\n",
    "print('MAE: ' + str(mae) + '\\nRMSE: ' + str(mse) + '\\nLOG(RMSE): ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error metrics show that HYMOD performs reasonably well, the MAE is around 1 $m^3/s$, the RMSE is on the order of 10% of the largest observed streamflow and the LOG(RMSE) is fairly low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Global Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sensitivity'></a> \n",
    "## 2.1- Experimental Design and Setup\n",
    "\n",
    "Now we'll examine how sensitive streamflow simulations generated by HYMOD are to the model's input parameters. We'll perform global sensitivity analysis (see Section 3.1 of the main text) using the SALib Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.analyze import delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first and critical step when conducting sensitivity analysis is determining the experimental design (see Design of Experiments, Section 3.4 of the main text). Our experimental design involves defining the uncertainties that we'll be examining, the output of interest, the ranges of each uncertainty that will be explored and the strategy for sampling the uncertainty space.\n",
    "\n",
    "For this experiment we'll explore the five parameters highlighted in Figure 1. We'll draw their ranges from existing literature on the model (note Jon H. paper). We'll use a Sobol sampling an  a quasi-random sampling with low sequences approach to sample the uncertainty space (Section 3.3.4).\n",
    "\n",
    "In this demonstration we'll utilize Sobol Sensitivity Analysis, a variance based method (Section 3.4.5). \n",
    "\n",
    "To explore HYMOD's behavoir, we'll examine the sensitivity of four model ouputs to input parameters: 1) predicted flow, 2) Mean Absolute Error (compared with the calibaration data set), 3) Root Mean Square Error and 4) Log Root Mean Square Error.\n",
    "\n",
    "This analysis will employ SALib, a Python implementation also utilized in the other SA tutorial (make this more formal).\n",
    "\n",
    "To start our analysis, we'll create a dictionary that describes our model uncertainties and their ranges, this dictionary is named \"problem_hymod\" (SALib refers to these dictionaries as \"problems\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_hymod = {\n",
    "    'num_vars': 5,\n",
    "    'names': ['Kq', 'Ks', 'Alp', 'Huz', 'B'],\n",
    "    'bounds': [[0.1, 1],  # Kq\n",
    "               [0, 0.1],  # Ks\n",
    "               [0, 1],    # Alp\n",
    "               [0.1, 500],  # Huz\n",
    "               [0, 1.9]]  # B             \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our uncertainites and ranges, we'll use SALib to sample the uncertainty space and run the model for each of the sample sets. We will load a sample that has already been created `param_values_hymod` for demonstration purposes. For HYMOD, literature recommends running at least N = 10,000 samples, to keep this demonstration easy to run however, we utilize only 256 sobol samples of uncertainties. To generate accurate approximations of second order sensitivity indicies SALib generates N*(2k+2) sets of samples, where N=256 and k=5 (number of uncertainties). For the math behind why this is needed, see (Saltelli, A., 2002. Making best use of model evaluations to compute sensitivity indices. Computer Physics Communications 145, 280–297. https://doi.org/10.1016/S0010-4655(02)00280-1).\n",
    "\n",
    "\n",
    "The actual model simulation takes an extended period, so we also load the simulation data from a previous run. The following demonstrates how to conduct this analysis:\n",
    "```python\n",
    "\n",
    "# generate 256 samples.\n",
    "param_values_hymod = saltelli.sample(problem_hymod, 256)\n",
    "\n",
    "# dictionary to store outputs in\n",
    "d_outputs = {}\n",
    "\n",
    "# run simulation for each parameter sample\n",
    "for i in range(0, len(param_values_hymod)):\n",
    "    \n",
    "    # run model for each sensitivity analysis parameter sets\n",
    "    hymod_output = msdbook.hymod(Nq, \n",
    "                                 param_values_hymod[i, 0], \n",
    "                                 param_values_hymod[i, 1], \n",
    "                                 param_values_hymod[i, 2], \n",
    "                                 param_values_hymod[i, 3], \n",
    "                                 param_values_hymod[i, 4], \n",
    "                                 leaf_data, \n",
    "                                 ndays=4015)\n",
    "    \n",
    "    # store the simulated total flow discharge\n",
    "    d_outputs[f\"Q{i}\"] = hymod_output[\"Q\"]\n",
    "\n",
    "    \n",
    "Q_df_bw = pd.DataFrame(d_outputs)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously generated parameter values \n",
    "param_values_hymod = msdbook.load_hymod_params()\n",
    "\n",
    "# number of samples\n",
    "n_samples = len(param_values_hymod)\n",
    "\n",
    "# load previously generated hymod simulated outputs\n",
    "Q_df_bw = msdbook.load_hymod_simulation()\n",
    "\n",
    "# column names of each sample simulation number\n",
    "sample_column_names = [i for i in Q_df_bw.columns if i[0] == 'Q']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running HYMOD - Model Warm-up\n",
    "A hydrological model such as HYMOD usually includes ordinary differential equations that are sensitive to their initial condition. They also have components in their underlying formulation that have long memory such that prior time steps can affect their current simulations. For example, soil moisture or groundwater can hold water for a long time and therefore they are often considered to exhibit a long memory. This can affect the partitioning of water to runoff and infiltration, while also controlling the generation of base flow. Therefore, it is important to have a reasonable initial value for them. To achieve this, hydrologists usually extend their simulation period and after the simulations, they remove that extended time period that has unreasonable groundwater or surface water values. This time period is called the warm-up time period.\n",
    "\n",
    "Here we extended our simulation for one year (from 10 years to 11 years) and we removed the first year of simulation, therefore our warm-up period is one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the first year of simulation from the simulations and reset the index\n",
    "Q_df = Q_df_bw.iloc[365:4015].copy().reset_index(drop=True)\n",
    "\n",
    "# exclude the first year of the input data and reset the index\n",
    "leaf_data = leaf_data.iloc[365:4015].copy().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that HYMOD has been warmed up, we'll examine how HYMOD's streamflow outputs vary under different sample sets, and compare them with the observed streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date columns to our simulation data frame; for this data our start date is 1/1/2000\n",
    "date_ts = pd.date_range(start='1/1/2000', periods=3650, freq='D')\n",
    "Q_df['date'] = date_ts\n",
    "Q_df['year'] = date_ts.year\n",
    "Q_df['month'] = date_ts.month\n",
    "Q_df['day'] = date_ts.day\n",
    "\n",
    "# aggregate the simulated observed streamflow to monthly mean\n",
    "df_sim_mth_mean = Q_df.groupby(['year', 'month'])[sample_column_names].mean()\n",
    "\n",
    "# do the same for the observed data\n",
    "date_ts = pd.date_range(start='1/1/2000', periods=len(leaf_data), freq='D')\n",
    "leaf_data['date'] = date_ts\n",
    "leaf_data['year'] = date_ts.year\n",
    "leaf_data['month'] = date_ts.month\n",
    "leaf_data['day'] = date_ts.day\n",
    "\n",
    "# aggregate the daily observed streamflow to monthly mean\n",
    "df_obs_mth_mean = leaf_data.groupby(['year', 'month']).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> View the source code used to create this plot here:  <a href=\"https://immm-sfa.github.io/msd_uncertainty_ebook/docs/html/A3_plotting_code.html#plot-observed-vs-sensitivity-streamflow\">plot_observed_vs_sensitivity_streamflow</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msdbook.plot_observed_vs_sensitivity_streamflow(df_obs=df_obs_mth_mean, \n",
    "                                                     df_sim=df_sim_mth_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sa_metrics'></a> \n",
    "### 2.2 - Sensitivity of streamflows to model parameters\n",
    "\n",
    "Now we'll examine how each of HYMOD's parameters impact the variance of simulated streamflows. Using SALib we'll calculate the first order and total order sensitivity indicies of each model parameter. The first order sensitivity index measure's the individual impact that a given parameter has on the variance of the simulated streamflows. The total order index measures the impact of a given parameter along with all interactions that other parameters have with the given parameter on simulated streamflows.\n",
    "\n",
    "We'll start with an matrix, Y, which contains our simulated streamflows for every uncertainty sample. We'll then use the sobol.analyze function from SALib to calculate the sensitivity indicies (Si). The arguments for this function are the problem dictionary defined in part 2.2 of this tutorial, and the matrix of simulated streamflows, Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall aggregated indices\n",
    "Y = Q_df[sample_column_names].mean().to_numpy()\n",
    "\n",
    "# Perform analysis\n",
    "Si = sobol.analyze(problem_hymod, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine our results, we'll print the first order and total order Si's for each parameter, then visualize the results with bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First order indices = ', Si['S1'])\n",
    "\n",
    "print('Total order indicies = ', Si['ST'])\n",
    "\n",
    "# suppress fixed formatter warning from ipykernel\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.bar(np.arange(5), Si['S1'])\n",
    "ax1.set_xticklabels(['','Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "ax1.set_ylabel('First order Si')\n",
    "ax1.set_ylim([0,1])\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.bar(np.arange(5), Si['ST'])\n",
    "ax2.set_xticklabels(['','Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "ax2.set_ylabel('Total order Si')\n",
    "ax2.set_ylim([0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our findings indicate that in this instance, the streamflow estimate from HYMOD is highly sensitive to soil moisture parameters Huz and B and hardly affected by the routing parameters. Notably, there is very little interactions between parameters causing the total order indicies to be nearly identical to the first order indicies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='diff_performance'></a> \n",
    "## 2.3 How do different performance metrics affect the results of our sensitivity analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamflow has many different properties. In this section, we discuss how the selection of metrics can lead to fundamentally different sensitivity analysis results. For example, one can only focus on aggregated streamflow metrics such as mean (what has been presented so far), or only on extreme events such as drought or floods.\n",
    "\n",
    "Here we compare three different metrics:\n",
    "1- Mean error (ME) 2- Root Mean Square Error (RMSE) 3- Log-Root Mean Square Error (Log(RMSE))\n",
    "\n",
    "Each of these metrics focuses on a specific attribute of streamflow. For example, RMSE highlights the impacts of extreme flood events, while LOG(RMSE) focuses on model performance during low-flow events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error metrics\n",
    "mae = Q_df[sample_column_names].apply(lambda x: abs(x-leaf_data[\"Strmflw\"]), axis=0)\n",
    "mse = Q_df[sample_column_names].apply(lambda x: metrics.mean_squared_error(x, leaf_data[\"Strmflw\"]), axis=0)\n",
    "rmse = mse**(1/2)\n",
    "\n",
    "# add error metrics to a dictionary\n",
    "d_metrics = {'MAE': mae.mean().values,\n",
    "             'RMSE': rmse.values,\n",
    "             'LOG[RMSE]': np.log10(rmse.values)}\n",
    "\n",
    "# convert to a dataframe\n",
    "df_metrics_SA = pd.DataFrame(d_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following to calculate the SA indices for each metric and visualize it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_s1_result = pd.DataFrame(np.zeros((3, 5)), columns=['Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "df_metric_sT_result = pd.DataFrame(np.zeros((3, 5)), columns=['Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "\n",
    "# conduct sensitivity analysis for each metric\n",
    "for index, i in enumerate(d_metrics.keys()):\n",
    "    \n",
    "    # get the data as a numpy array for the target metric\n",
    "    Y = d_metrics[i]\n",
    "    \n",
    "    # use the metric to conduct SA\n",
    "    Si = sobol.analyze(problem_hymod, Y, print_to_console=False)\n",
    "    \n",
    "    # add the sensitivity indices to the output data frame\n",
    "    df_metric_s1_result.iloc[index, :] = Si['S1']\n",
    "    df_metric_sT_result.iloc[index, :] = Si['ST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seaborn heatmap with required labels\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "# labels for y-axis\n",
    "y_axis_labels = ['Mean Absoulte Error', 'RSME', 'Log(RMSE)']\n",
    "\n",
    "# plot heatmap\n",
    "ax1 = sns.heatmap(df_metric_s1_result, yticklabels=y_axis_labels, annot=True,  cmap='inferno_r', cbar_kws={'label': 'Si'}, cbar=False)\n",
    "ax1.figure.axes[-1].yaxis.label.set_size(14)\n",
    "ax1.set_title('First Order Sensitivity')\n",
    "                 \n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2 = sns.heatmap(df_metric_sT_result, yticklabels=y_axis_labels, annot=True,  cmap='inferno_r', cbar_kws={'label': 'Si'})\n",
    "ax2.figure.axes[-1].yaxis.label.set_size(14)\n",
    "ax2.set_title('Total Order Sensitivity')\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order sensitivity indicies indicate that HYMOD's sensitivity to its parameters is different depending on how its output is measured. Unsurprisingly, the mean absolute error is highly sensitive to the soil moisture accounting parameters Huz and B, just like the overall streamflow predictions above. However, when we examine RMSE and log(RMSE), the routing parameters Alp become sensitive, and the sensitivity to parameter B is reduced. As described above, RMSE and LOG(RMSE) respond to model performance in high-flow and low flow periods respectively. Our results indicate that for these flow regimes Alp, the parameter that governs the split between quick and slow flow is an important factor. While still the parameter with the highest most effect on all three measures, Huz is much less influential for RMSE and LOG(RMSE) than it is for MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total order sensitivity indicies review a different, more complex story. While the MAE sensitivity is relatively governed by first order effects (like the streamflow predictions above), the RMSE and LOG(RMSE) error metrics show significant interactions. Alp has the highest total order sensitivity for RMSE and is eqal to Huz for Log(RMSE). Kq, which has a relatively low first order sensitivity index, shows strong contribution to variance when interactions are taken into account.\n",
    "\n",
    "Radial convergence plots are a helpful way to visualize the interactions between parameters. These plots array the model parameters in a circle and plot the first order, total order and second order Sobol sensitivity indices for each parameter. The first order sensitivity is shown as the size of a closed circle, the total order as the size of a larger open circle and the second order as the thickness of a line connecting two parameters. Below is an example of a radial convergence plot for the LOG(RMSE) measure. The plot indicates strong interactions between the Huz and Alp parameters, as well as Alp and Kq. There is also an interaction between Alp and Ks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "sns.set_style('whitegrid', {'axes_linewidth': 0, 'axes.edgecolor': 'white'})\n",
    " \n",
    "    \n",
    "def is_significant(value, confidence_interval, threshold=\"conf\"):\n",
    "    if threshold == \"conf\":\n",
    "        return value - abs(confidence_interval) > 0\n",
    "    else:\n",
    "        return value - abs(float(threshold)) > 0\n",
    "\n",
    "\n",
    "def grouped_radial(SAresults, parameters, radSc=2.0, scaling=1, widthSc=0.5, STthick=1, varNameMult=1.3, colors=None, groups=None, gpNameMult=1.5, threshold=\"conf\"):\n",
    "    # Derived from https://github.com/calvinwhealton/SensitivityAnalysisPlots\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    color_map = {}\n",
    "     \n",
    "    # initialize parameters and colors\n",
    "    if groups is None:\n",
    "         \n",
    "        if colors is None:\n",
    "            colors = [\"k\"]\n",
    "         \n",
    "        for i, parameter in enumerate(parameters):\n",
    "            color_map[parameter] = colors[i % len(colors)]\n",
    "    else:        \n",
    "        if colors is None:\n",
    "            colors = sns.color_palette(\"deep\", max(3, len(groups)))\n",
    "         \n",
    "        for i, key in enumerate(groups.keys()):\n",
    "            #parameters.extend(groups[key])\n",
    "             \n",
    "            for parameter in groups[key]:\n",
    "                color_map[parameter] = colors[i % len(colors)]\n",
    "     \n",
    "    n = len(parameters)\n",
    "    angles = radSc*math.pi*np.arange(0, n)/n\n",
    "    x = radSc*np.cos(angles)\n",
    "    y = radSc*np.sin(angles)\n",
    "     \n",
    "    # plot second-order indices\n",
    "    for i, j in itertools.combinations(range(n), 2):\n",
    "        #key1 = parameters[i]\n",
    "        #key2 = parameters[j]\n",
    "         \n",
    "        if is_significant(SAresults[\"S2\"][i][j], SAresults[\"S2_conf\"][i][j], threshold):\n",
    "            angle = math.atan((y[j]-y[i])/(x[j]-x[i]))\n",
    "                 \n",
    "            if y[j]-y[i] < 0:\n",
    "                angle += math.pi\n",
    "                 \n",
    "            line_hw = scaling*(max(0, SAresults[\"S2\"][i][j])**widthSc)/2\n",
    "                 \n",
    "            coords = np.empty((4, 2))\n",
    "            coords[0, 0] = x[i] - line_hw*math.sin(angle)\n",
    "            coords[1, 0] = x[i] + line_hw*math.sin(angle)\n",
    "            coords[2, 0] = x[j] + line_hw*math.sin(angle)\n",
    "            coords[3, 0] = x[j] - line_hw*math.sin(angle)\n",
    "            coords[0, 1] = y[i] + line_hw*math.cos(angle)\n",
    "            coords[1, 1] = y[i] - line_hw*math.cos(angle)\n",
    "            coords[2, 1] = y[j] - line_hw*math.cos(angle)\n",
    "            coords[3, 1] = y[j] + line_hw*math.cos(angle)\n",
    " \n",
    "            ax.add_artist(plt.Polygon(coords, color=\"0.75\"))\n",
    "         \n",
    "    # plot total order indices\n",
    "    for i, key in enumerate(parameters):\n",
    "        if is_significant(SAresults[\"ST\"][i], SAresults[\"ST_conf\"][i], threshold):\n",
    "            ax.add_artist(plt.Circle((x[i], y[i]), scaling*(SAresults[\"ST\"][i]**widthSc)/2, color='w'))\n",
    "            ax.add_artist(plt.Circle((x[i], y[i]), scaling*(SAresults[\"ST\"][i]**widthSc)/2, lw=STthick, color='0.4', fill=False))\n",
    "     \n",
    "    # plot first-order indices\n",
    "    for i, key in enumerate(parameters):\n",
    "        if is_significant(SAresults[\"S1\"][i], SAresults[\"S1_conf\"][i], threshold):\n",
    "            ax.add_artist(plt.Circle((x[i], y[i]), scaling*(SAresults[\"S1\"][i]**widthSc)/2, color='0.4'))\n",
    "            \n",
    "    # add labels\n",
    "    for i, key in enumerate(parameters):                \n",
    "        ax.text(varNameMult*x[i], varNameMult*y[i], key, ha='center', va='center',\n",
    "                rotation=angles[i]*360/(2*math.pi) - 90,\n",
    "                color=color_map[key])\n",
    "         \n",
    "    if groups is not None:\n",
    "        for i, group in enumerate(groups.keys()):\n",
    "            print(group)\n",
    "            group_angle = np.mean([angles[j] for j in range(n) if parameters[j] in groups[group]])\n",
    "             \n",
    "            ax.text(gpNameMult*radSc*math.cos(group_angle), gpNameMult*radSc*math.sin(group_angle), group, ha='center', va='center',\n",
    "                rotation=group_angle*360/(2*math.pi) - 90,\n",
    "                color=colors[i % len(colors)])\n",
    "             \n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.axis('equal')\n",
    "    plt.axis([-2*radSc, 2*radSc, -2*radSc, 2*radSc])\n",
    "    #plt.show()\n",
    " \n",
    "     \n",
    "    return fig\n",
    "\n",
    "# define groups for parameter uncertainties\n",
    "groups={\"Soil Moisture\" : [\"Huz\", \"B\"],\n",
    "        \"Routing\" : [\"Alp\", \"Kq\", \"Ks\"]}\n",
    " \n",
    " \n",
    "fig = grouped_radial(Si, ['Kq', 'Ks', 'Alp', 'Huz', 'B'], groups=groups, threshold=0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TVSA'></a> \n",
    "## 2.4 Time-Varying Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 2.5 we saw how performing sensitivity analysis on different measurements of model output can yeild in different results on the importance of each uncertain input. In this section we'll examine how performing this analysis over time can yeild additional insight into the performance of HYMOD. We'll first examine how model sensitivities vary by month, then examine how they change across each year of the simulation.\n",
    "\n",
    "For this demonstration, we'll focus only on the monthly streamflow predictions generated by HYMOD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Sensitivity analysis indices for each month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate simulated streamflow data to monthly time series\n",
    "df_sim_by_mth_mean = Q_df.groupby('month')[sample_column_names].mean()\n",
    "\n",
    "# aggregate observed streamflow data to monthly time series\n",
    "df_obs_by_mth_mean = leaf_data.groupby('month').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following to calculate the SA indices for each month and visualize it. Results are pre-loaded for efficiency.\n",
    "```python\n",
    "# set up dataframes to store outputs\n",
    "df_mth_s1 = pd.DataFrame(np.zeros((12,5)), columns=['Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "df_mth_delta = df_mth_s1.copy()\n",
    "\n",
    "# iterate through each month\n",
    "for i in range(0, 12):\n",
    "    \n",
    "    # generate the simulation data\n",
    "    Y = df_sim_by_mth_mean.iloc[i, :].to_numpy()\n",
    "    \n",
    "    # run SA\n",
    "    Si = delta.analyze(problem_hymod, param_values_hymod, Y, print_to_console=False)\n",
    "    \n",
    "    # add to output dataframes\n",
    "    df_mth_s1.iloc[i, :] = np.maximum(Si['S1'], 0)\n",
    "    df_mth_delta.iloc[i, :] = np.maximum(Si['delta'], 0)  \n",
    "    \n",
    "# convert to arrays\n",
    "arr_mth_s1 = df_mth_s1.values\n",
    "arr_mth_delta = df_mth_delta.values\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First-order Indices\n",
    "The following can be used to visualize the time-varying first-order indices. The first order represents the direct impacts of a specific parameter on model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> View the source code used to create this plot here:  <a href=\"https://immm-sfa.github.io/msd_uncertainty_ebook/docs/html/A3_plotting_code.html#plot-monthly-heatmap\">plot_monthly_heatmap</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously ran data\n",
    "arr_mth_delta, arr_mth_s1 = msdbook.load_hymod_monthly_simulations()\n",
    "\n",
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_monthly_heatmap(arr_sim=arr_mth_s1.T,\n",
    "                                       df_obs=df_obs_by_mth_mean,\n",
    "                                       title='First Order - Mean Monthly SA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure demonstrates the first order sensitivity indices when the streamflow data are aggregated by month. The purple line represents the observed monthly discharge. The figure indicates that the first order indices are highest for B and Huz across all months and lowest for Alp, Ks, and Kq. Note that in the months with the highest flow, Ks becomes an influential parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total-order indices\n",
    "We can also focus on the total order sensitivity index that includes first-order SA indices and interactions between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_monthly_heatmap(arr_sim=arr_mth_delta.T,\n",
    "                                       df_obs=df_obs_by_mth_mean,\n",
    "                                       title='Total Order - Mean monthly SA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, the total order sensitivity results are different than the first order sensitivity results, which indicates that interactions between the parameters (particularly in regards to routing parameters $Kq$, $Ks$, and $Alp$) contribute to changes in HYMOD output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Annual sensitivity analysis indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by year and get mean\n",
    "df_sim_by_yr_mean = Q_df.groupby(['year'])[sample_column_names].mean()\n",
    "\n",
    "# group input data and get mean\n",
    "df_obs_by_yr_mean = leaf_data.groupby(['year']).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the sensitivity analysis indices for each individual year. This will allow us to understand if model control changes during different years. The following code first aggregates the outputs to annual time steps, and then calculates the SA indices.\n",
    "```python\n",
    "# set up dataframes to store outputs\n",
    "df_yr_s1 = pd.DataFrame(np.zeros((10, 5)), columns=['Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "df_yr_delta = df_yr_s1.copy()\n",
    "\n",
    "# iterate through each year\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    # generate the simulation data\n",
    "    Y = df_sim_by_yr_mean.iloc[i, :].to_numpy()\n",
    "    \n",
    "    # run SA\n",
    "    Si = delta.analyze(problem_hymod, param_values_hymod, Y, print_to_console=False)\n",
    "    \n",
    "    # add to output dataframes\n",
    "    df_yr_s1.iloc[i, :] = np.maximum(Si['S1'], 0)\n",
    "    df_yr_delta.iloc[i, :] = np.maximum(Si['delta'], 0)  \n",
    "    \n",
    "# convert to arrays\n",
    "arr_yr_s1 = df_mth_s1.values\n",
    "arr_yr_delta = df_mth_delta.values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First-order indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> View the source code used to create this plot here:  <a href=\"https://immm-sfa.github.io/msd_uncertainty_ebook/docs/html/A3_plotting_code.html#plot-annual-heatmap\">plot_annual_heatmap</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously ran data\n",
    "arr_yr_delta, arr_yr_s1 = msdbook.load_hymod_annual_simulations()\n",
    "\n",
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_annual_heatmap(arr_sim=arr_yr_s1.T, \n",
    "                                      df_obs=df_obs_by_yr_mean,\n",
    "                                      title='First Order - Mean Annual SA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order sensitivities at the annual scale are not unlike the first order monthly sensitivities. Once again, sensitivities vary across year and Huz and B are the most consequential parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total-order indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_annual_heatmap(arr_sim=arr_yr_delta.T, \n",
    "                                      df_obs=df_obs_by_yr_mean,\n",
    "                                      title='Total Order - Mean Annual SA and Observed flow')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results indicate that sensitivity analysis indices vary in different years and now that interactions are included, the Kq, Ks, and Alp variables impact the sensitivity of the streamflow output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Monthly time-varying sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although time-varying sensitivity analysis (TVSA) at average monthly and average annual temporal resolutions is informative, TVSA is susceptible to the aggregation issue that we discussed earlier in section 3-2. To avoid that we can further discretize our time domain to zoom into individual months. This will provide us with even more information about model behavior and the sensitivity of different parameters in different states of the system. The block of code demonstrates how to implement the monthly TVSA.\n",
    "```python\n",
    "# set up dataframes to store outputs\n",
    "df_vary_s1 = pd.DataFrame(np.zeros((df_obs_mth_mean.shape[0], 5)), \n",
    "                          columns=['Kq', 'Ks', 'Alp', 'Huz', 'B'])\n",
    "\n",
    "df_vary_delta = df_vary_s1.copy()\n",
    "\n",
    "# iterate through each month\n",
    "for i in range(0, df_obs_mth_mean.shape[0]):\n",
    "    \n",
    "    # generate the simulation data\n",
    "    Y = df_sim_mth_mean.iloc[i, :].to_numpy()\n",
    "    \n",
    "    # run SA\n",
    "    Si = delta.analyze(problem_hymod, param_values_hymod, Y, print_to_console=False)\n",
    "    \n",
    "    # add to output dataframes\n",
    "    df_vary_s1.iloc[i, :] = np.maximum(Si['S1'], 0)\n",
    "    df_vary_delta.iloc[i, :] = np.maximum(Si['delta'], 0)  \n",
    "    \n",
    "# convert to arrays\n",
    "arr_vary_s1 = df_vary_s1.values\n",
    "arr_vary_delta = df_vary_delta.values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First-order indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> View the source code used to create this plot here:  <a href=\"https://immm-sfa.github.io/msd_uncertainty_ebook/docs/html/A3_plotting_code.html#plot-varying-heatmap\">plot_varying_heatmap</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in previously ran data\n",
    "arr_vary_delta, arr_vary_s1 = msdbook.load_hymod_varying_simulations()\n",
    "\n",
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_varying_heatmap(arr_sim=arr_vary_s1.T, \n",
    "                                      df_obs=df_obs_mth_mean,\n",
    "                                      title='First Order - Time-Varying SA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the TVSA when streamflow was aggregated, this figure suggests that Kq is indeed a relevant parameter for influencing streamflow output when individual months are considered.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total order - time varying sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "ax, ax2 = msdbook.plot_varying_heatmap(arr_sim=arr_vary_delta.T, \n",
    "                                      df_obs=df_obs_mth_mean,\n",
    "                                      title='Total Order - Time-Varying SA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, the total order sensitivities further indicate the importance of Kq that is not apparent if aggregation is utilized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips to Apply this methodology to your own problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrated how to use global sensitivtiy analysis to explore a complex, non-linear model. We showed how measuring sensitivity across multiple measures of model performance and temporal aggregations yeilding differing results about model sensitivity/behavoir. While these results may seem contraditory, they provide useful insight into the behavoir of HYMOD. Would we  expect the same parameters to control high flow and low flow regimes within the model? Maybe, depending on the system, but also, maybe not. This analysis can provide insight into how the model responds to its input parameters, allowing us to compare the results to our expectaions. This may allow us to find problems with our intial assumptions, or call attention to model features that can be improved or expanded upon. Depending on the model and context, it may also yield insight into the workings of the underlying system.\n",
    "\n",
    "To run this tutorial on your own model you will need to:\n",
    "\n",
    "1. Design your experiment by choosing sampling bounds for your parameters and setting up the problem dictionary as in step 2-2\n",
    "2. Choose the parameters of interest\n",
    "2. Generate samples using the saltelli.sample function. This step is problem-dependent and note that the Sobol method can be computationally intensive depending on the model being analyzed. More complex models will be slower to run and will also require more samples to calculate accurate estimates of Sobol indices. Once you complete this process, pay attention to the confidence bounds on your sensitivity indices to see whether you need to run more samples.\n",
    "4. Run the parameter sets through your model and record each of the desired model outputs.\n",
    "5. Calculate the Sobol indices for each performance criteria. Now, the Y will be a numpy array with your external model output and you will need to include the parameter samples as an additional argument.\n",
    "6. Follow the procedure in step 2.6 to disaggregate performance across time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_msd",
   "language": "python",
   "name": "py3.9.4_msd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
